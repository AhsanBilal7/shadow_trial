{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 512, 7, 7])\n",
      "1 torch.Size([1, 4, 320, 320])\n",
      "xi:  torch.Size([1, 4, 320, 320])\n",
      "y torch.Size([1, 102400, 32])\n",
      "1 torch.Size([1, 102400, 32])\n",
      "conv3:  torch.Size([1, 1600, 256])\n",
      "40\n",
      "torch.Size([1, 256, 40, 40])\n",
      "torch.Size([1, 1600, 256])\n",
      "output:  torch.Size([1, 3, 320, 320])\n",
      "Input shape: torch.Size([1, 3, 320, 320])\n",
      "Total Parameters: 12558164\n",
      "Output shape: torch.Size([1, 3, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "from torch import einsum\n",
    "import cv2\n",
    "import scipy.misc\n",
    "import utils\n",
    "\n",
    "from torch.nn import init\n",
    "class ECAAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.gap=nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv=nn.Conv1d(1,1,kernel_size=kernel_size,padding=(kernel_size-1)//2)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y=self.gap(x) #bs,c,1,1\n",
    "        y=y.squeeze(-1).permute(0,2,1) #bs,1,c\n",
    "        y=self.conv(y) #bs,1,c\n",
    "        y=self.sigmoid(y) #bs,1,c\n",
    "        y=y.permute(0,2,1).unsqueeze(-1) #bs,c,1,1\n",
    "        return x*y.expand_as(x)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input=torch.randn(50,512,7,7)\n",
    "    eca = ECAAttention(kernel_size=3)\n",
    "    output=eca(input)\n",
    "    print(output.shape)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self,channel,reduction=16):\n",
    "        super().__init__()\n",
    "        self.maxpool=nn.AdaptiveMaxPool2d(1)\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d(1)\n",
    "        self.se=nn.Sequential(\n",
    "            nn.Conv2d(channel,channel//reduction,1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channel//reduction,channel,1,bias=False)\n",
    "        )\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        max_result=self.maxpool(x)\n",
    "        avg_result=self.avgpool(x)\n",
    "        max_out=self.se(max_result)\n",
    "        avg_out=self.se(avg_result)\n",
    "        output=self.sigmoid(max_out+avg_out)\n",
    "        return output\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self,kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv=nn.Conv2d(2,1,kernel_size=kernel_size,padding=kernel_size//2)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        max_result,_=torch.max(x,dim=1,keepdim=True)\n",
    "        avg_result=torch.mean(x,dim=1,keepdim=True)\n",
    "        result=torch.cat([max_result,avg_result],1)\n",
    "        output=self.conv(result)\n",
    "        output=self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class CBAMBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, channel=512,reduction=16,kernel_size=49):\n",
    "        super().__init__()\n",
    "        self.ca=ChannelAttention(channel=channel,reduction=reduction)\n",
    "        self.sa=SpatialAttention(kernel_size=kernel_size)\n",
    "        self.sk = ECAAttention(kernel_size=7)\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        residual=x\n",
    "        out=x*self.ca(x)\n",
    "        out=out*self.sa(out)\n",
    "        # print(\"------------\",out.shape)\n",
    "        out = out*self.sk(out)\n",
    "  \n",
    "        # print(\"------------\",out.shape)\n",
    "        return out+residual\n",
    "\n",
    "\n",
    "#########################################\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, strides=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.strides = strides\n",
    "        self.in_channel=in_channel\n",
    "        self.out_channel=out_channel\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=strides, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=strides, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        self.conv11 = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=strides, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.block(x)\n",
    "        out2 = self.conv11(x)\n",
    "        out = out1 + out2\n",
    "        return out\n",
    "\n",
    "    def flops(self, H, W): \n",
    "        flops = H*W*self.in_channel*self.out_channel*(3*3+1)+H*W*self.out_channel*self.out_channel*3*3\n",
    "        return flops\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, block=ConvBlock,dim=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.ConvBlock1 = ConvBlock(4, dim, strides=1)\n",
    "        self.pool1 = nn.Conv2d(dim,dim,kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.ConvBlock2 = block(dim, dim*2, strides=1)\n",
    "        self.pool2 = nn.Conv2d(dim*2,dim*2,kernel_size=4, stride=2, padding=1)\n",
    "       \n",
    "        self.ConvBlock3 = block(dim*2, dim*4, strides=1)\n",
    "        self.pool3 = nn.Conv2d(dim*4,dim*4,kernel_size=4, stride=2, padding=1)\n",
    "       \n",
    "        self.ConvBlock4 = block(dim*4, dim*8, strides=1)\n",
    "        self.pool4 = nn.Conv2d(dim*8, dim*8,kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.ConvBlock5 = block(dim*8, dim*16, strides=1)\n",
    "\n",
    "        self.upv6 = nn.ConvTranspose2d(dim*16, dim*8, 2, stride=2)\n",
    "        self.ConvBlock6 = block(dim*16, dim*8, strides=1)\n",
    "\n",
    "        self.upv7 = nn.ConvTranspose2d(dim*8, dim*4, 2, stride=2)\n",
    "        self.ConvBlock7 = block(dim*8, dim*4, strides=1)\n",
    "\n",
    "        self.upv8 = nn.ConvTranspose2d(dim*4, dim*2, 2, stride=2)\n",
    "        self.ConvBlock8 = block(dim*4, dim*2, strides=1)\n",
    "\n",
    "        self.upv9 = nn.ConvTranspose2d(dim*2, dim, 2, stride=2)\n",
    "        self.ConvBlock9 = block(dim*2, dim, strides=1)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(dim, 3, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.ConvBlock1(x)\n",
    "        pool1 = self.pool1(conv1)\n",
    "\n",
    "        conv2 = self.ConvBlock2(pool1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "\n",
    "        conv3 = self.ConvBlock3(pool2)\n",
    "        pool3 = self.pool3(conv3)\n",
    "\n",
    "        conv4 = self.ConvBlock4(pool3)\n",
    "        pool4 = self.pool4(conv4)\n",
    "\n",
    "        conv5 = self.ConvBlock5(pool4)\n",
    "\n",
    "        up6 = self.upv6(conv5)\n",
    "        up6 = torch.cat([up6, conv4], 1)\n",
    "        conv6 = self.ConvBlock6(up6)\n",
    "\n",
    "        up7 = self.upv7(conv6)\n",
    "        up7 = torch.cat([up7, conv3], 1)\n",
    "        conv7 = self.ConvBlock7(up7)\n",
    "\n",
    "        up8 = self.upv8(conv7)\n",
    "        up8 = torch.cat([up8, conv2], 1)\n",
    "        conv8 = self.ConvBlock8(up8)\n",
    "\n",
    "        up9 = self.upv9(conv8)\n",
    "        up9 = torch.cat([up9, conv1], 1)\n",
    "        conv9 = self.ConvBlock9(up9)\n",
    "\n",
    "        conv10 = self.conv10(conv9)\n",
    "        out = x + conv10\n",
    "\n",
    "        return out\n",
    "\n",
    "    def flops(self, H, W): \n",
    "        flops = 0\n",
    "        flops += self.ConvBlock1.flops(H, W)\n",
    "        flops += H/2*W/2*self.dim*self.dim*4*4\n",
    "        flops += self.ConvBlock2.flops(H/2, W/2)\n",
    "        flops += H/4*W/4*self.dim*2*self.dim*2*4*4\n",
    "        flops += self.ConvBlock3.flops(H/4, W/4)\n",
    "        flops += H/8*W/8*self.dim*4*self.dim*4*4*4\n",
    "        flops += self.ConvBlock4.flops(H/8, W/8)\n",
    "        flops += H/16*W/16*self.dim*8*self.dim*8*4*4\n",
    "\n",
    "        flops += self.ConvBlock5.flops(H/16, W/16)\n",
    "\n",
    "        flops += H/8*W/8*self.dim*16*self.dim*8*2*2\n",
    "        flops += self.ConvBlock6.flops(H/8, W/8)\n",
    "        flops += H/4*W/4*self.dim*8*self.dim*4*2*2\n",
    "        flops += self.ConvBlock7.flops(H/4, W/4)\n",
    "        flops += H/2*W/2*self.dim*4*self.dim*2*2*2\n",
    "        flops += self.ConvBlock8.flops(H/2, W/2)\n",
    "        flops += H*W*self.dim*2*self.dim*2*2\n",
    "        flops += self.ConvBlock9.flops(H, W)\n",
    "\n",
    "        flops += H*W*self.dim*3*3*3\n",
    "        return flops\n",
    "\n",
    "#########################################\n",
    "class PosCNN(nn.Module):\n",
    "    def __init__(self, in_chans, embed_dim=768, s=1):\n",
    "        super(PosCNN, self).__init__()\n",
    "        self.proj = nn.Sequential(nn.Conv2d(in_chans, embed_dim, 3, s, 1, bias=True, groups=embed_dim))\n",
    "        self.s = s\n",
    "\n",
    "    def forward(self, x, H=None, W=None):\n",
    "        B, N, C = x.shape\n",
    "        H = H or int(math.sqrt(N))\n",
    "        W = W or int(math.sqrt(N))\n",
    "        feat_token = x\n",
    "        cnn_feat = feat_token.transpose(1, 2).view(B, C, H, W)\n",
    "        if self.s == 1:\n",
    "            x = self.proj(cnn_feat) + cnn_feat\n",
    "        else:\n",
    "            x = self.proj(cnn_feat)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "    def no_weight_decay(self):\n",
    "        return ['proj.%d.weight' % i for i in range(4)]\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B, N, C]\n",
    "        x = torch.transpose(x, 1, 2)  # [B, C, N]\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        x = x * y.expand_as(x)\n",
    "        x = torch.transpose(x, 1, 2)  # [B, N, C]\n",
    "        return x\n",
    "\n",
    "class SepConv2d(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=0,\n",
    "                 dilation=1,act_layer=nn.ReLU):\n",
    "        super(SepConv2d, self).__init__()\n",
    "        self.depthwise = torch.nn.Conv2d(in_channels,\n",
    "                                         in_channels,\n",
    "                                         kernel_size=kernel_size,\n",
    "                                         stride=stride,\n",
    "                                         padding=padding,\n",
    "                                         dilation=dilation,\n",
    "                                         groups=in_channels)\n",
    "        self.pointwise = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.act_layer = act_layer() if act_layer is not None else nn.Identity()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.act_layer(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W): \n",
    "        flops = 0\n",
    "        flops += H*W*self.in_channels*self.kernel_size**2/self.stride**2\n",
    "        flops += H*W*self.in_channels*self.out_channels\n",
    "        return flops\n",
    "\n",
    "##########################################################################\n",
    "## Channel Attention Layer\n",
    "class CALayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16, bias=False):\n",
    "        super(CALayer, self).__init__()\n",
    "        # global average pooling: feature --> point\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        # feature channel downscale and upscale --> channel weight\n",
    "        self.conv_du = nn.Sequential(\n",
    "                nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=bias),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=bias),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.conv_du(y)\n",
    "        return x * y\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, bias=False, stride = 1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size,\n",
    "        padding=(kernel_size//2), bias=bias, stride = stride)\n",
    "\n",
    "##########################################################################\n",
    "## Channel Attention Block (CAB)\n",
    "class CAB(nn.Module):\n",
    "    def __init__(self, n_feat, kernel_size, reduction, bias, act):\n",
    "        super(CAB, self).__init__()\n",
    "        modules_body = []\n",
    "        modules_body.append(conv(n_feat, n_feat, kernel_size, bias=bias))\n",
    "        modules_body.append(act)\n",
    "        modules_body.append(conv(n_feat, n_feat, kernel_size, bias=bias))\n",
    "\n",
    "        self.CA = CALayer(n_feat, reduction, bias=bias)\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x)\n",
    "        res = self.CA(res)\n",
    "        res += x\n",
    "        return res\n",
    "\n",
    "#########################################\n",
    "######## Embedding for q,k,v ########\n",
    "class ConvProjection(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, kernel_size=3, q_stride=1, k_stride=1, v_stride=1, dropout = 0.,\n",
    "                 last_stage=False,bias=True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        pad = (kernel_size - q_stride)//2\n",
    "        self.to_q = SepConv2d(dim, inner_dim, kernel_size, q_stride, pad, bias)\n",
    "        self.to_k = SepConv2d(dim, inner_dim, kernel_size, k_stride, pad, bias)\n",
    "        self.to_v = SepConv2d(dim, inner_dim, kernel_size, v_stride, pad, bias)\n",
    "\n",
    "    def forward(self, x, attn_kv=None):\n",
    "        b, n, c, h = *x.shape, self.heads\n",
    "        l = int(math.sqrt(n))\n",
    "        w = int(math.sqrt(n))\n",
    "\n",
    "        attn_kv = x if attn_kv is None else attn_kv\n",
    "        x = rearrange(x, 'b (l w) c -> b c l w', l=l, w=w)\n",
    "        attn_kv = rearrange(attn_kv, 'b (l w) c -> b c l w', l=l, w=w)\n",
    "        # print(attn_kv)\n",
    "        q = self.to_q(x)\n",
    "        q = rearrange(q, 'b (h d) l w -> b h (l w) d', h=h)\n",
    "        \n",
    "        k = self.to_k(attn_kv)\n",
    "        v = self.to_v(attn_kv)\n",
    "        k = rearrange(k, 'b (h d) l w -> b h (l w) d', h=h)\n",
    "        v = rearrange(v, 'b (h d) l w -> b h (l w) d', h=h)\n",
    "        return q,k,v    \n",
    "    \n",
    "    def flops(self, H, W): \n",
    "        flops = 0\n",
    "        flops += self.to_q.flops(H, W)\n",
    "        flops += self.to_k.flops(H, W)\n",
    "        flops += self.to_v.flops(H, W)\n",
    "        return flops\n",
    "\n",
    "class LinearProjection(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0., bias=True):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = bias)\n",
    "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = bias)\n",
    "        self.dim = dim\n",
    "        self.inner_dim = inner_dim\n",
    "\n",
    "    def forward(self, x, attn_kv=None):\n",
    "        B_, N, C = x.shape\n",
    "        attn_kv = x if attn_kv is None else attn_kv\n",
    "        q = self.to_q(x).reshape(B_, N, 1, self.heads, C // self.heads).permute(2, 0, 3, 1, 4)\n",
    "        kv = self.to_kv(attn_kv).reshape(B_, N, 2, self.heads, C // self.heads).permute(2, 0, 3, 1, 4)\n",
    "        q = q[0]\n",
    "        k, v = kv[0], kv[1] \n",
    "        return q,k,v\n",
    "\n",
    "    def flops(self, H, W): \n",
    "        flops = H*W*self.dim*self.inner_dim*3\n",
    "        return flops \n",
    "\n",
    "class LinearProjection_Concat_kv(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0., bias=True):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = bias)\n",
    "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = bias)\n",
    "        self.dim = dim\n",
    "        self.inner_dim = inner_dim\n",
    "\n",
    "    def forward(self, x, attn_kv=None):\n",
    "        B_, N, C = x.shape\n",
    "        attn_kv = x if attn_kv is None else attn_kv\n",
    "        qkv_dec = self.to_qkv(x).reshape(B_, N, 3, self.heads, C // self.heads).permute(2, 0, 3, 1, 4)\n",
    "        kv_enc = self.to_kv(attn_kv).reshape(B_, N, 2, self.heads, C // self.heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k_d, v_d = qkv_dec[0], qkv_dec[1], qkv_dec[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "        k_e, v_e = kv_enc[0], kv_enc[1] \n",
    "        k = torch.cat((k_d,k_e),dim=2)\n",
    "        v = torch.cat((v_d,v_e),dim=2)\n",
    "        return q,k,v\n",
    "\n",
    "    def flops(self, H, W): \n",
    "        flops = H*W*self.dim*self.inner_dim*5\n",
    "        return flops \n",
    "\n",
    "#########################################\n",
    "\n",
    "########### SIA #############\n",
    "class WindowAttention(nn.Module):\n",
    "    def __init__(self, dim, win_size, num_heads, token_projection='linear', qkv_bias=True, qk_scale=None, attn_drop=0.,\n",
    "                 proj_drop=0., se_layer=False):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.win_size = win_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        # define a parameter table of relative position bias\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * win_size[0] - 1) * (2 * win_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.win_size[0])  # [0,...,Wh-1]\n",
    "        coords_w = torch.arange(self.win_size[1])  # [0,...,Ww-1]\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += self.win_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += self.win_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.win_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "        # self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        if token_projection == 'conv':\n",
    "            self.qkv = ConvProjection(dim, num_heads, dim // num_heads, bias=qkv_bias)\n",
    "        elif token_projection == 'linear_concat':\n",
    "            self.qkv = LinearProjection_Concat_kv(dim, num_heads, dim // num_heads, bias=qkv_bias)\n",
    "        else:\n",
    "            self.qkv = LinearProjection(dim, num_heads, dim // num_heads, bias=qkv_bias)\n",
    "\n",
    "        self.token_projection = token_projection\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        # self.se_layer = SELayer(dim)\n",
    "        self.ll = nn.Identity()\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, xm, attn_kv=None, mask=None):\n",
    "        B_, N, C = x.shape\n",
    "        # x = self.se_layer(x)\n",
    "        one = torch.ones_like(xm)\n",
    "        zero = torch.zeros_like(xm)\n",
    "        xm = torch.where(xm < 0.1, one, one*2)\n",
    "        mm = xm @ xm.transpose(-2, -1)\n",
    "        one = torch.ones_like(mm)\n",
    "        mm = torch.where(mm==2, one, one*0.2)\n",
    "        mm = torch.unsqueeze(mm, dim=1)\n",
    "        q, k, v = self.qkv(x, attn_kv)\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1)) * mm\n",
    "\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.win_size[0] * self.win_size[1], self.win_size[0] * self.win_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        ratio = attn.size(-1) // relative_position_bias.size(-1)\n",
    "        relative_position_bias = repeat(relative_position_bias, 'nH l c -> nH l (c d)', d=ratio)\n",
    "\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            mask = repeat(mask, 'nW m n -> nW m (n d)', d=ratio)\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N * ratio) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N * ratio)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.ll(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, win_size={self.win_size}, num_heads={self.num_heads}'\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        # calculate flops for 1 window with token length of N\n",
    "        # print(N, self.dim)\n",
    "        flops = 0\n",
    "        N = self.win_size[0] * self.win_size[1]\n",
    "        nW = H * W / N\n",
    "        # qkv = self.qkv(x)\n",
    "        # flops += N * self.dim * 3 * self.dim\n",
    "        flops += self.qkv.flops(H, W)\n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "        if self.token_projection != 'linear_concat':\n",
    "            flops += nW * self.num_heads * N * (self.dim // self.num_heads) * N\n",
    "            #  x = (attn @ v)\n",
    "            flops += nW * self.num_heads * N * N * (self.dim // self.num_heads)\n",
    "        else:\n",
    "            flops += nW * self.num_heads * N * (self.dim // self.num_heads) * N * 2\n",
    "            #  x = (attn @ v)\n",
    "            flops += nW * self.num_heads * N * N * 2 * (self.dim // self.num_heads)\n",
    "        # x = self.proj(x)\n",
    "        flops += nW * N * self.dim * self.dim\n",
    "        print(\"W-MSA:{%.2f}\" % (flops / 1e9))\n",
    "        return flops\n",
    "\n",
    "\n",
    "#########################################\n",
    "########### feed-forward network #############\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # fc1\n",
    "        flops += H*W*self.in_features*self.hidden_features \n",
    "        # fc2\n",
    "        flops += H*W*self.hidden_features*self.out_features\n",
    "        print(\"MLP:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "class LeFF(nn.Module):\n",
    "    def __init__(self, dim=32, hidden_dim=128, act_layer=nn.GELU,drop = 0.):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Sequential(nn.Linear(dim, hidden_dim),\n",
    "                                act_layer())\n",
    "        self.dwconv = nn.Sequential(nn.Conv2d(hidden_dim,hidden_dim,groups=hidden_dim,kernel_size=3,stride=1,padding=1),\n",
    "                        act_layer())\n",
    "        self.linear2 = nn.Sequential(nn.Linear(hidden_dim, dim))\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, img_size=(128,128)):\n",
    "        # bs x hw x c\n",
    "        bs, hw, c = x.size()\n",
    "        # hh = int(math.sqrt(hw))\n",
    "        hh = img_size[0]\n",
    "        ww = img_size[1]\n",
    "\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        # spatial restore\n",
    "        x = rearrange(x, ' b (h w) (c) -> b c h w ', h = hh, w = ww)\n",
    "        # bs,hidden_dim,32x32\n",
    "\n",
    "        x = self.dwconv(x)\n",
    "\n",
    "        # flaten\n",
    "        x = rearrange(x, ' b c h w -> b (h w) c', h = hh, w = ww)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # fc1\n",
    "        flops += H*W*self.dim*self.hidden_dim \n",
    "        # dwconv\n",
    "        flops += H*W*self.hidden_dim*3*3\n",
    "        # fc2\n",
    "        flops += H*W*self.hidden_dim*self.dim\n",
    "        print(\"LeFF:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "#########################################\n",
    "########### window operation#############\n",
    "def window_partition(x, win_size, dilation_rate=1):\n",
    "    B, H, W, C = x.shape\n",
    "    if dilation_rate !=1:\n",
    "        x = x.permute(0,3,1,2) # B, C, H, W\n",
    "        assert type(dilation_rate) is int, 'dilation_rate should be a int'\n",
    "        x = F.unfold(x, kernel_size=win_size,dilation=dilation_rate,padding=4*(dilation_rate-1),stride=win_size) # B, C*Wh*Ww, H/Wh*W/Ww\n",
    "        windows = x.permute(0,2,1).contiguous().view(-1, C, win_size, win_size) # B' ,C ,Wh ,Ww\n",
    "        windows = windows.permute(0,2,3,1).contiguous() # B' ,Wh ,Ww ,C\n",
    "    else:\n",
    "        x = x.view(B, H // win_size, win_size, W // win_size, win_size, C)\n",
    "        windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, win_size, win_size, C) # B' ,Wh ,Ww ,C\n",
    "    return windows\n",
    "\n",
    "def window_reverse(windows, win_size, H, W, dilation_rate=1):\n",
    "    # B' ,Wh ,Ww ,C\n",
    "    B = int(windows.shape[0] / (H * W / win_size / win_size))\n",
    "    x = windows.view(B, H // win_size, W // win_size, win_size, win_size, -1)\n",
    "    if dilation_rate !=1:\n",
    "        x = windows.permute(0,5,3,4,1,2).contiguous() # B, C*Wh*Ww, H/Wh*W/Ww\n",
    "        x = F.fold(x, (H, W), kernel_size=win_size, dilation=dilation_rate, padding=4*(dilation_rate-1),stride=win_size)\n",
    "    else:\n",
    "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x\n",
    "\n",
    "#########################################\n",
    "# Downsample Block\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Downsample, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=4, stride=2, padding=1),\n",
    "        )\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "\n",
    "    def forward(self, x, img_size=(128,128)):\n",
    "        B, L, C = x.shape\n",
    "        H = img_size[0]\n",
    "        W = img_size[1]\n",
    "        x = x.transpose(1, 2).contiguous().view(B, C, H, W)\n",
    "        out = self.conv(x).flatten(2).transpose(1,2).contiguous()  # B H*W C\n",
    "        return out\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # conv\n",
    "        flops += H/2*W/2*self.in_channel*self.out_channel*4*4\n",
    "        print(\"Downsample:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "# Upsample Block\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channel, out_channel, kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        \n",
    "    def forward(self, x, img_size=(128,128)):\n",
    "        B, L, C = x.shape\n",
    "        H = img_size[0]\n",
    "        W = img_size[1]\n",
    "        x = x.transpose(1, 2).contiguous().view(B, C, H, W)\n",
    "        out = self.deconv(x).flatten(2).transpose(1,2).contiguous() # B H*W C\n",
    "        return out\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # conv\n",
    "        flops += H*2*W*2*self.in_channel*self.out_channel*2*2 \n",
    "        print(\"Upsample:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "# Input Projection\n",
    "class InputProj(nn.Module):\n",
    "    def __init__(self, in_channel=3, out_channel=64, kernel_size=3, stride=1, norm_layer=None,act_layer=nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=kernel_size//2),\n",
    "            act_layer(inplace=True)\n",
    "        )\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(out_channel)\n",
    "        else:\n",
    "            self.norm = None\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2).contiguous()  # B H*W C\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # conv\n",
    "        flops += H*W*self.in_channel*self.out_channel*3*3\n",
    "\n",
    "        if self.norm is not None:\n",
    "            flops += H*W*self.out_channel \n",
    "        print(\"Input_proj:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "# Output Projection\n",
    "class OutputProj(nn.Module):\n",
    "    def __init__(self, in_channel=64, out_channel=3, kernel_size=3, stride=1, norm_layer=None,act_layer=None):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=kernel_size//2),\n",
    "        )\n",
    "        if act_layer is not None:\n",
    "            self.proj.add_module(act_layer(inplace=True))\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(out_channel)\n",
    "        else:\n",
    "            self.norm = None\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "\n",
    "    def forward(self, x, img_size=(128,128)):\n",
    "        B, L, C = x.shape\n",
    "        H = img_size[0]\n",
    "        W = img_size[1]\n",
    "        # H = int(math.sqrt(L))\n",
    "        # W = int(math.sqrt(L))\n",
    "        x = x.transpose(1, 2).view(B, C, H, W)\n",
    "        x = self.proj(x)\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self, H, W):\n",
    "        flops = 0\n",
    "        # conv\n",
    "        flops += H*W*self.in_channel*self.out_channel*3*3\n",
    "\n",
    "        if self.norm is not None:\n",
    "            flops += H*W*self.out_channel \n",
    "        print(\"Output_proj:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "\n",
    "#########################################\n",
    "########### CA Transformer #############\n",
    "class CATransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, num_heads, win_size=10, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm, token_projection='linear', token_mlp='leff',\n",
    "                 se_layer=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.win_size = win_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.token_mlp = token_mlp\n",
    "        if min(self.input_resolution) <= self.win_size:\n",
    "            self.shift_size = 0\n",
    "            self.win_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.win_size, \"shift_size must in 0-win_size\"\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer,\n",
    "                       drop=drop) if token_mlp == 'ffn' else LeFF(dim, mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "        self.CAB = CAB(dim, kernel_size=3, reduction=4, bias=False, act=nn.PReLU())\n",
    "\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"win_size={self.win_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "    def forward(self, x, xm, mask=None, img_size=(128, 128)):\n",
    "        B, L, C = x.shape\n",
    "        H = img_size[0]\n",
    "        W = img_size[1]\n",
    "        assert L == W * H, \\\n",
    "            f\"Input image size ({H}*{W} doesn't match model ({L}).\"\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # spatial restore\n",
    "        x = rearrange(x, ' b (h w) (c) -> b c h w ', h=H, w=W)\n",
    "        # bs,hidden_dim,32x32\n",
    "\n",
    "        x = self.CAB(x)\n",
    "\n",
    "        # flaten\n",
    "        x = rearrange(x, ' b c h w -> b (h w) c', h=H, w=W)\n",
    "        x = x.view(B, H * W, C)\n",
    "\n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x), img_size=img_size))\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.input_resolution\n",
    "        # norm1\n",
    "        flops += self.dim * H * W\n",
    "        # W-MSA/SW-MSA\n",
    "        flops += self.attn.flops(H, W)\n",
    "        # norm2\n",
    "        flops += self.dim * H * W\n",
    "        # mlp\n",
    "        flops += self.mlp.flops(H, W)\n",
    "        print(\"LeWin:{%.2f}\" % (flops / 1e9))\n",
    "        return flops\n",
    "\n",
    "#########################################\n",
    "########### SIM Transformer #############\n",
    "class SIMTransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, num_heads, win_size=10, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm,token_projection='linear',token_mlp='leff',se_layer=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.win_size = win_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.token_mlp = token_mlp\n",
    "        if min(self.input_resolution) <= self.win_size:\n",
    "            self.shift_size = 0\n",
    "            self.win_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.win_size, \"shift_size must in 0-win_size\"\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, win_size=to_2tuple(self.win_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop,\n",
    "            token_projection=token_projection,se_layer=se_layer)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,act_layer=act_layer, drop=drop) if token_mlp=='ffn' else LeFF(dim,mlp_hidden_dim,act_layer=act_layer, drop=drop)\n",
    "        self.CAB = CAB(dim, kernel_size=3, reduction=4, bias=False, act=nn.PReLU())\n",
    "\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"win_size={self.win_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "    def forward(self, x, xm, mask=None, img_size = (128, 128)):\n",
    "        B, L, C = x.shape\n",
    "        H = img_size[0]\n",
    "        W = img_size[1]\n",
    "        assert L == W * H, \\\n",
    "            f\"Input image size ({H}*{W} doesn't match model ({L}).\"\n",
    "\n",
    "        ## input mask\n",
    "        if mask != None:\n",
    "            input_mask = F.interpolate(mask, size=(H,W)).permute(0,2,3,1)\n",
    "            input_mask_windows = window_partition(input_mask, self.win_size) # nW, win_size, win_size, 1\n",
    "            attn_mask = input_mask_windows.view(-1, self.win_size * self.win_size) # nW, win_size*win_size\n",
    "            attn_mask = attn_mask.unsqueeze(2)*attn_mask.unsqueeze(1) # nW, win_size*win_size, win_size*win_size\n",
    "            attn_mask = attn_mask.masked_fill(attn_mask!=0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "        else:\n",
    "            attn_mask = None\n",
    "\n",
    "        ## shift mask\n",
    "        if self.shift_size > 0:\n",
    "            # calculate attention mask for SW-MSA\n",
    "            shift_mask = torch.zeros((1, H, W, 1)).type_as(x)\n",
    "            h_slices = (slice(0, -self.win_size),\n",
    "                        slice(-self.win_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.win_size),\n",
    "                        slice(-self.win_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    shift_mask[:, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "            shift_mask_windows = window_partition(shift_mask, self.win_size)  # nW, win_size, win_size, 1\n",
    "            shift_mask_windows = shift_mask_windows.view(-1, self.win_size * self.win_size) # nW, win_size*win_size\n",
    "            shift_attn_mask = shift_mask_windows.unsqueeze(1) - shift_mask_windows.unsqueeze(2) # nW, win_size*win_size, win_size*win_size\n",
    "            shift_attn_mask = shift_attn_mask.masked_fill(shift_attn_mask != 0, float(-100.0)).masked_fill(shift_attn_mask == 0, float(0.0))\n",
    "            attn_mask = attn_mask + shift_attn_mask if attn_mask is not None else shift_attn_mask\n",
    "            \n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "\n",
    "\n",
    "\n",
    "        x = x.view(B, H, W, C)\n",
    "        xm = xm.permute(0, 2, 3, 1)\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "            shifted_m = torch.roll(xm, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "            shifted_m = xm\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.win_size)  # nW*B, win_size, win_size, C  N*C->C\n",
    "        x_windows = x_windows.view(-1, self.win_size * self.win_size, C)  # nW*B, win_size*win_size, C\n",
    "        m_windows = window_partition(shifted_m, self.win_size)  # nW*B, win_size, win_size, C  N*C->C\n",
    "        m_windows = m_windows.view(-1, self.win_size * self.win_size, 1)  # nW*B, win_size*win_size, C\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(x_windows, m_windows, mask=attn_mask)  # nW*B, win_size*win_size, C\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.win_size, self.win_size, C)\n",
    "\n",
    "\n",
    "        shifted_x = window_reverse(attn_windows, self.win_size, H, W)  # B H' W' C\n",
    "\n",
    "        # reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C)\n",
    "\n",
    "        x = rearrange(x, ' b (h w) (c) -> b c h w ', h=H, w=W)\n",
    "        # bs,hidden_dim,32x32\n",
    "\n",
    "        x = self.CAB(x)\n",
    "\n",
    "        # flaten\n",
    "        x = rearrange(x, ' b c h w -> b (h w) c', h=H, w=W)\n",
    "\n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x), img_size=img_size))\n",
    "\n",
    "        del attn_mask\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.input_resolution\n",
    "        # norm1\n",
    "        flops += self.dim * H * W\n",
    "        # W-MSA/SW-MSA\n",
    "        flops += self.attn.flops(H, W)\n",
    "        # norm2\n",
    "        flops += self.dim * H * W\n",
    "        # mlp\n",
    "        flops += self.mlp.flops(H,W)\n",
    "        print(\"LeWin:{%.2f}\"%(flops/1e9))\n",
    "        return flops\n",
    "\n",
    "\n",
    "#########################################\n",
    "########### Basic layer of ShadowFormer ################\n",
    "class BasicShadowFormer(nn.Module):\n",
    "    def __init__(self, dim, output_dim, input_resolution, depth, num_heads, win_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, use_checkpoint=False,\n",
    "                 token_projection='linear',token_mlp='ffn',se_layer=False,cab=False):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        # build blocks\n",
    "        if cab:\n",
    "            self.blocks = nn.ModuleList([\n",
    "                CATransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                      num_heads=num_heads, win_size=win_size,\n",
    "                                      shift_size=0 if (i % 2 == 0) else win_size // 2,\n",
    "                                      mlp_ratio=mlp_ratio,\n",
    "                                      qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                      drop=drop, attn_drop=attn_drop,\n",
    "                                      drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                      norm_layer=norm_layer, token_projection=token_projection, token_mlp=token_mlp,\n",
    "                                      se_layer=se_layer)\n",
    "                for i in range(depth)])\n",
    "        else:\n",
    "            self.blocks = nn.ModuleList([\n",
    "                SIMTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                     num_heads=num_heads, win_size=win_size,\n",
    "                                     shift_size=0 if (i % 2 == 0) else win_size // 2,\n",
    "                                     mlp_ratio=mlp_ratio,\n",
    "                                     qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                     drop=drop, attn_drop=attn_drop,\n",
    "                                     drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                     norm_layer=norm_layer,token_projection=token_projection,token_mlp=token_mlp,se_layer=se_layer)\n",
    "                for i in range(depth)])\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"    \n",
    "\n",
    "    def forward(self, x, xm, mask=None, img_size=(128,128)):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x, xm, mask, img_size)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        for blk in self.blocks:\n",
    "            flops += blk.flops()\n",
    "        return flops\n",
    "\n",
    "\n",
    "class ShadowFormer(nn.Module):\n",
    "    def __init__(self, img_size=256, in_chans=3,\n",
    "                 embed_dim=32, depths=[2, 2, 2, 2, 2, 2, 2, 2, 2], num_heads=[1, 2, 4, 8, 16, 16, 8, 4, 2],\n",
    "                 win_size=8, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=nn.LayerNorm, patch_norm=True,\n",
    "                 use_checkpoint=False, token_projection='linear', token_mlp='leff', se_layer=True,\n",
    "                 dowsample=Downsample, upsample=Upsample, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_enc_layers = len(depths)//2\n",
    "        self.num_dec_layers = len(depths)//2\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_norm = patch_norm\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.token_projection = token_projection\n",
    "        self.mlp = token_mlp\n",
    "        self.win_size =win_size\n",
    "        self.reso = img_size\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        # stochastic depth\n",
    "        enc_dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths[:self.num_enc_layers]))]\n",
    "        conv_dpr = [drop_path_rate]*depths[4]\n",
    "        dec_dpr = enc_dpr[::-1]\n",
    "\n",
    "        # build layers\n",
    "\n",
    "        # Input/Output\n",
    "        self.input_proj = InputProj(in_channel=4, out_channel=embed_dim, kernel_size=3, stride=1, act_layer=nn.LeakyReLU)\n",
    "        self.output_proj = OutputProj(in_channel=2*embed_dim, out_channel=in_chans, kernel_size=3, stride=1)\n",
    "        self.input_proj1 = InputProj(in_channel=256, out_channel=256, kernel_size=3, stride=1, act_layer=nn.LeakyReLU)\n",
    "        self.output_proj2 = OutputProj(in_channel=256, out_channel=256, kernel_size=3, stride=1)\n",
    "        # self.CAB = CAB(embed_dim, kernel_size=3, reduction=4, bias=False, act=nn.PReLU())\n",
    "\n",
    "        # Encoder\n",
    "        self.encoderlayer_0 = BasicShadowFormer(dim=embed_dim,\n",
    "                            output_dim=embed_dim,\n",
    "                            input_resolution=(img_size,\n",
    "                                                img_size),\n",
    "                            depth=depths[0],\n",
    "                            num_heads=num_heads[0],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=enc_dpr[sum(depths[:0]):sum(depths[:1])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,se_layer=se_layer,cab=True)\n",
    "        self.dowsample_0 = dowsample(embed_dim, embed_dim*2)\n",
    "        self.encoderlayer_1 = BasicShadowFormer(dim=embed_dim*2,\n",
    "                            output_dim=embed_dim*2,\n",
    "                            input_resolution=(img_size // 2,\n",
    "                                                img_size // 2),\n",
    "                            depth=depths[1],\n",
    "                            num_heads=num_heads[1],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=enc_dpr[sum(depths[:1]):sum(depths[:2])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,se_layer=se_layer, cab=True)\n",
    "        self.dowsample_1 = dowsample(embed_dim*2, embed_dim*4)\n",
    "        self.encoderlayer_2 = BasicShadowFormer(dim=embed_dim*4,\n",
    "                            output_dim=embed_dim*4,\n",
    "                            input_resolution=(img_size // (2 ** 2),\n",
    "                                                img_size // (2 ** 2)),\n",
    "                            depth=depths[2],\n",
    "                            num_heads=num_heads[2],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=enc_dpr[sum(depths[:2]):sum(depths[:3])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,se_layer=se_layer)\n",
    "        self.dowsample_2 = dowsample(embed_dim*4, embed_dim*8)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.conv = BasicShadowFormer(dim=embed_dim*8,\n",
    "                            output_dim=embed_dim*8,\n",
    "                            input_resolution=(img_size // (2 ** 3),\n",
    "                                                img_size // (2 ** 3)),\n",
    "                            depth=depths[4],\n",
    "                            num_heads=num_heads[4],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=conv_dpr,\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,se_layer=se_layer)\n",
    "\n",
    "        # # Decoder\n",
    "        self.upsample_0 = upsample(embed_dim*8, embed_dim*4)\n",
    "        self.decoderlayer_0 = BasicShadowFormer(dim=embed_dim*8,\n",
    "                            output_dim=embed_dim*8,\n",
    "                            input_resolution=(img_size // (2 ** 2),\n",
    "                                                img_size // (2 ** 2)),\n",
    "                            depth=depths[6],\n",
    "                            num_heads=num_heads[6],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=dec_dpr[sum(depths[5:6]):sum(depths[5:7])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,se_layer=se_layer)\n",
    "        self.upsample_1 = upsample(embed_dim*8, embed_dim*2)\n",
    "        self.decoderlayer_1 = BasicShadowFormer(dim=embed_dim*4,\n",
    "                            output_dim=embed_dim*4,\n",
    "                            input_resolution=(img_size // 2,\n",
    "                                                img_size // 2),\n",
    "                            depth=depths[7],\n",
    "                            num_heads=num_heads[7],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=dec_dpr[sum(depths[5:7]):sum(depths[5:8])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,se_layer=se_layer, cab=True)\n",
    "        self.upsample_2 = upsample(embed_dim*4, embed_dim)\n",
    "        self.decoderlayer_2 = BasicShadowFormer(dim=embed_dim*2,\n",
    "                            output_dim=embed_dim*2,\n",
    "                            input_resolution=(img_size,\n",
    "                                                img_size),\n",
    "                            depth=depths[8],\n",
    "                            num_heads=num_heads[8],\n",
    "                            win_size=win_size,\n",
    "                            mlp_ratio=self.mlp_ratio,\n",
    "                            qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                            drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                            drop_path=dec_dpr[sum(depths[5:8]):sum(depths[5:9])],\n",
    "                            norm_layer=norm_layer,\n",
    "                            use_checkpoint=use_checkpoint,\n",
    "                            token_projection=token_projection,token_mlp=token_mlp,se_layer=se_layer,cab=True)\n",
    "        self.apply(self._init_weights)\n",
    "        self.cbam = CBAMBlock(channel=256)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'absolute_pos_embed'}\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {'relative_position_bias_table'}\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"embed_dim={self.embed_dim}, token_projection={self.token_projection}, token_mlp={self.mlp},win_size={self.win_size}\"\n",
    "\n",
    "    def forward(self, x, xm, mask=None):\n",
    "        # Input  Projection\n",
    "        xi = torch.cat((x, xm), dim=1)\n",
    "        print(\"1\",xi.shape)\n",
    "        self.img_size = (x.shape[2], x.shape[3])\n",
    "        print(\"xi: \", xi.shape)\n",
    "        y = self.input_proj(xi)\n",
    "        print(\"y\",y.shape)\n",
    "        y = self.pos_drop(y)\n",
    "        print(\"1\",y.shape)\n",
    "\n",
    "        #Encoder\n",
    "        conv0 = self.encoderlayer_0(y, xm, mask=mask, img_size = self.img_size)\n",
    "        pool0 = self.dowsample_0(conv0, img_size = self.img_size)\n",
    "        m = nn.MaxPool2d(2)\n",
    "        xm1 = m(xm)\n",
    "        self.img_size = (int(self.img_size[0]/2), int(self.img_size[1]/2))\n",
    "        conv1 = self.encoderlayer_1(pool0, xm1, mask=mask, img_size = self.img_size)\n",
    "        pool1 = self.dowsample_1(conv1, img_size = self.img_size)\n",
    "        m = nn.MaxPool2d(2)\n",
    "        xm2 = m(xm1)\n",
    "        self.img_size = (int(self.img_size[0] / 2), int(self.img_size[1] / 2))\n",
    "        conv2 = self.encoderlayer_2(pool1, xm2, mask=mask, img_size = self.img_size)\n",
    "        pool2 = self.dowsample_2(conv2, img_size = self.img_size)\n",
    "        self.img_size = (int(self.img_size[0] / 2), int(self.img_size[1] / 2))\n",
    "        m = nn.MaxPool2d(2)\n",
    "        xm3 = m(xm2)\n",
    "\n",
    "        # Bottleneck\n",
    "        conv3 = self.conv(pool2, xm3, mask=mask, img_size = self.img_size)\n",
    "        print(\"conv3: \",conv3.shape)\n",
    "        # ---------------------------------------------\n",
    "        temp_img_size = int(np.sqrt(conv3.shape[1]))\n",
    "        print(temp_img_size)\n",
    "        conv3 =self.output_proj2(conv3, img_size=(temp_img_size,temp_img_size))\n",
    "        print(conv3.shape)\n",
    "        conv3 = self.cbam(conv3)\n",
    "        conv3 =self.input_proj1(conv3)\n",
    "        print(conv3.shape)\n",
    "        # ---------------------------------------------\n",
    "        #Decoder\n",
    "        up0 = self.upsample_0(conv3, img_size = self.img_size)\n",
    "        self.img_size = (int(self.img_size[0] * 2), int(self.img_size[1] * 2))\n",
    "        deconv0 = torch.cat([up0,conv2],-1)\n",
    "        deconv0 = self.decoderlayer_0(deconv0, xm2, mask=mask, img_size = self.img_size)\n",
    "\n",
    "        up1 = self.upsample_1(deconv0, img_size = self.img_size)\n",
    "        self.img_size = (int(self.img_size[0] * 2), int(self.img_size[1] * 2))\n",
    "        deconv1 = torch.cat([up1,conv1],-1)\n",
    "        deconv1 = self.decoderlayer_1(deconv1, xm1, mask=mask, img_size = self.img_size)\n",
    "\n",
    "        up2 = self.upsample_2(deconv1, img_size = self.img_size)\n",
    "        self.img_size = (int(self.img_size[0] * 2), int(self.img_size[1] * 2))\n",
    "        deconv2 = torch.cat([up2,conv0],-1)\n",
    "        deconv2 = self.decoderlayer_2(deconv2, xm, mask=mask, img_size = self.img_size)\n",
    "\n",
    "        # Output Projection\n",
    "        y = self.output_proj(deconv2, img_size = self.img_size) + x\n",
    "        print(\"output: \", y.shape)\n",
    "        return y\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming ShadowFormer and other required classes like BasicShadowFormer, Downsample, Upsample are defined\n",
    "# or imported already\n",
    "\n",
    "# Create a sample input tensor\n",
    "input_tensor = torch.randn(1, 3, 320, 320)  # Batch size of 1, 3 channels (RGB), 256x256 image\n",
    "mask_tensor = torch.randn(1, 1, 320, 320)  # Corresponding mask tensor\n",
    "\n",
    "# Instantiate the model\n",
    "model = ShadowFormer()\n",
    "# ShadowFormer(img_size=opt.train_ps,embed_dim=opt.embed_dim,win_size=opt.win_size,token_projection=opt.token_projection,token_mlp=opt.token_mlp)\n",
    "\n",
    "# Forward pass through the model\n",
    "total_parameters = sum(p.numel() for p in model.parameters())\n",
    "output = model(input_tensor, mask_tensor)\n",
    "\n",
    "\n",
    "# Print input and output shapes\n",
    "print(f\"Input shape: {input_tensor.shape}\")\n",
    "print(f\"Total Parameters: {total_parameters}\")\n",
    "print(f\"Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': '0034467960_02', 'company': 'Nucor', 'instruction': 'Following is an investment thesis about Nucor. List questions that must be answered to write about the risks regarding the thesis.', 'source': 'Nucor is one of the highest quality companies in the steel space in terms of asset quality, management and capital allocation, as illustrated by its through-the-cycle free cash flow generation. Versus peers, Nucor trades at a premium and currently has an ambitious set of expansion projects underway, including the Brandenburg plate mill, and the recently announced sheet mill.', 'q&a': '[\" What is Nucor\\'s current market share in the steel industry?\", \\' What is the expected revenue growth rate for Nucor in the next 5 years?\\', \" What is the expected cost of production for Nucor\\'s new sheet mill?\", \" How does Nucor\\'s EBITDA margin compare to its peers in the steel industry?\", \" What percentage of Nucor\\'s revenue comes from international sales?\", \\' How much does Nucor spend on research and development annually?\\', \" What is the utilization rate of Nucor\\'s existing facilities?\", \" What is the expected return on investment for Nucor\\'s new Brandenburg plate mill?\", \\' How much debt does Nucor currently have on its balance sheet?\\', \" What is the expected payback period for Nucor\\'s new sheet mill investment?\", \\' How does Nucor plan to stay competitive in an increasingly crowded steel market?\\', \" How will the ongoing trade tensions and tariffs impact Nucor\\'s business?\", \" What is Nucor\\'s approach to sustainability and environmental responsibility?\", \\' How does Nucor attract and retain top talent in the steel industry?\\', \" How does Nucor\\'s management team prioritize capital allocation decisions?\"]'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"amphora/sFIOG\", \"InvestmentThesis-to-Question\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': '0034467960_02', 'company': 'Nucor', 'instruction': 'Following is an investment thesis about Nucor. List questions that must be answered to write about the risks regarding the thesis.', 'source': 'Nucor is one of the highest quality companies in the steel space in terms of asset quality, management and capital allocation, as illustrated by its through-the-cycle free cash flow generation. Versus peers, Nucor trades at a premium and currently has an ambitious set of expansion projects underway, including the Brandenburg plate mill, and the recently announced sheet mill.', 'q&a': '[\" What is Nucor\\'s current market share in the steel industry?\", \\' What is the expected revenue growth rate for Nucor in the next 5 years?\\', \" What is the expected cost of production for Nucor\\'s new sheet mill?\", \" How does Nucor\\'s EBITDA margin compare to its peers in the steel industry?\", \" What percentage of Nucor\\'s revenue comes from international sales?\", \\' How much does Nucor spend on research and development annually?\\', \" What is the utilization rate of Nucor\\'s existing facilities?\", \" What is the expected return on investment for Nucor\\'s new Brandenburg plate mill?\", \\' How much debt does Nucor currently have on its balance sheet?\\', \" What is the expected payback period for Nucor\\'s new sheet mill investment?\", \\' How does Nucor plan to stay competitive in an increasingly crowded steel market?\\', \" How will the ongoing trade tensions and tariffs impact Nucor\\'s business?\", \" What is Nucor\\'s approach to sustainability and environmental responsibility?\", \\' How does Nucor attract and retain top talent in the steel industry?\\', \" How does Nucor\\'s management team prioritize capital allocation decisions?\"]'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
